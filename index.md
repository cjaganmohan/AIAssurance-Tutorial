# AIA Assurance Tutorial 

## Overview
The wide scale adoption AI will require that AI engineers and developers can provide assurances to the user base that an algorithm will perform as intended and without failure. Assurance is the safety valve for reliable, dependable, explainable, and fair intelligent systems. AI assurance provides the necessary tools to enable AI adoption into applications, software, hardware, and complex systems. AI assurance involves quantifying capabilities and associating risks across deployments including: data quality to include inherent biases, algorithm performance, statistical errors, and algorithm trustworthiness and security. Data, algorithmic, and context/domain-specific factors may change over time and impact the ability of AI systems in delivering accurate outcomes. In this tutorial, we discuss the importance and different angles of AI assurance, and present a general framework that addresses its challenges. 

This tutorial covers the major aspects of AI assurance; it will be organized into three parts. First, we will introduce and present the challenges in testing and evaluating AI systems. The remainder of the session (i.e. parts 2 and 3) will be an interactive. In part 2, we will introduce the new assurance metrics for AI systems such as explainability, fairness, and trustworthiness followed by a discussion and involvement by the audience. In the third part of the session, the attendees will be encouraged to participate in an open-discussion setup to exchange ideas and challenges in AI assurance based on their own experiences, we aim to cover different angles of assurance, for instance, ones that arise due to the domain in which an AI system is deployed, the architecture of the AI system itself, and ones related to government and policy regulations. We will conclude the tutorial with a discussion on the future of AI assurance and a feedback poll (lessons learned) from the participants. 

## Outline

### Part 1: Introduction to AI Assurance
  - Validation and Verification - Traditional Software vs AI Software

  - Testing beyond Correctness - the need for new assurance methods

### Part 2: The Six AI Assurance Goals (Interactive Session)
  1. Explainable AI

  2. Trustworthy AI

  3. Safe AI

  4. Secure AI

  5. Fair AI

  6. Ethical AI

### Part 3: AI Assurance Challenges (Interactive Session)
- AI Assurance around the world - an overview

- AI Assurance adoption into different challenges

- The Future of AI Assurance


## Presenters

### Jaganmohan Chandrasekaran, Virginia Tech

[Jaganmohan Chandrasekaran](https://cjaganmohan.github.io) is a postdoctoral research associate at the Commonwealth Cyber Initiative (CCI) at Virginia Tech. He obtained his Ph.D. from the University of Texas at Arlington. His research interests are at the intersection of Software Engineering and Artificial Intelligence, focusing on the reliability and trustworthiness of AI-based software systems. His current research focuses on developing AI assurance approaches using Causal Inference. His work has been published at peer-reviewed international conferences.

### Feras A. Batarseh, Virginia Tech
[Feras A. Batarseh](https://cyberinitiative.org/research/researcher-directory/batarseh-feras.html) is a Research Associate Professor with the Bradley Department of Electrical and Computer Engineering at Virginia Tech (VT). His research spans the areas of AI for Public Policy, AI Assurance, Agricultural Economics, and Data Engineering. His work has been published at various prestigious journals and international conferences. Additionally, Dr. Batarseh published multiple chapters and books, his two recent books are: "Federal Data Science: Transforming Government and Agricultural Policy Using AI" and "Data Democracy: At the Nexus of AI, Software Development, and Knowledge Engineering", both by Elsevier’s Academic Press. Dr. Batarseh is a Commonwealth Cyber Initiative (CCI) fellow, an affiliate with the Center for Advanced Innovation in Agriculture (CAIA) at VT, and a senior member of the Institute of Electrical and Electronics Engineers (IEEE); he is also a member of the Agricultural and Applied Economics Association (AAEA), and the Association for the Advancement of Artificial Intelligence (AAAI). He has taught AI and Data Science courses at multiple universities including George Mason University (GMU), University of Maryland - Baltimore County (UMBC), Georgetown University, and George Washington University (GWU). Dr. Batarseh obtained his Ph.D. and M.Sc. in Computer Engineering from the University of Central Florida (UCF) (2007, 2011), a Graduate Certificate in Project Leadership from Cornell University (2016), and another in Public Policy Economics from the University of Oxford (2020).

### Laura Freeman, Virginia Tech
[Laura Freeman](https://www.stat.vt.edu/people/stat-faculty/freeman-laura.html) is a Research Associate Professor in the Statistics Department at Virginia Tech and director of the Intelligent Systems Lab in the Hume Center for National Security and Technology. She received all of her degrees from Virginia Tech: a B.S. in aerospace engineering with a minor in mathematics in 2005; an M.S. and Ph.D., both in statistics, in 2006 and 2010 respectively. Her research focuses on Experimental methods for assurance of cyber-physical systems, data science, AI, and ML.

### D. Richard Kuhn, NIST
[D. Richard Kuhn](https://www.nist.gov/people/d-richard-kuhn) is a computer scientist in the Computer Security Division at NIST and is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE).  His research focuses on combinatorial methods in software verification and testing (csrc.nist.gov/acts), and extending these methods for assurance and explainability in AI and machine learning.

### M S Raunak, NIST
[M S Raunak](https://www.nist.gov/people/m-s-raunak) is a Computer Scientist at the Computer Security Division in the National Institute of Standards and Technology (NIST), Gaithersburg, USA. His research interests include verification, validation, and assurance of ‘difficult-to-test’ systems such as complex simulation models, cryptographic implementations, and machine learning algorithms. He is currently focused on developing metrics, tools, and techniques for developing explainable and trustworthy artificial intelligence and machine learning systems. Dr. Raunak earned in M.S. and Ph.D. degrees from the computer science department at University of Massachusetts Amherst. He is a member of the IEEE.

### Raghu N. Kacker, NIST
[Raghu N. Kacker](https://www.nist.gov/people/raghu-n-kacker) is a scientist in the National Institute of Standards and Technology (NIST), Gaithersburg, MD 20899, USA. His research interests include testing of software-based systems for trust and security, and mathematics of measurement. He received his Ph.D. from the Iowa State University. He is a Fellow of the American Statistical Association and a Fellow of the American Society for Quality.

## Supplementary Materials
To be updated soon
